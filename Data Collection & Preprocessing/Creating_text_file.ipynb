{"cells":[{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"0a17faccfaa843e5b49a342a382743e8","deepnote_cell_type":"text-cell-p"},"source":"","block_group":"927c264ea1324eafb7a8284ab4edf1c5"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1719249807990,"execution_millis":4811,"deepnote_to_be_reexecuted":false,"cell_id":"4442d7846173437b9af14eb129b3e0d0","deepnote_cell_type":"code"},"source":"!pip install conllu\nimport numpy as np \nimport pandas as pd\nimport time\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nimport os\nimport random","block_group":"8787cd5e2e334c9fb2c83ff15481d791","execution_count":null,"outputs":[{"name":"stdout","text":"Collecting conllu\n  Downloading conllu-4.5.3-py2.py3-none-any.whl (16 kB)\nInstalling collected packages: conllu\nSuccessfully installed conllu-4.5.3\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/29073238-ad9a-42c8-8074-a08cbf771baf","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1719249801309,"execution_millis":50,"deepnote_to_be_reexecuted":false,"cell_id":"901e8396eb714528ae3677f13765888d","deepnote_cell_type":"code"},"source":"!pip install mtranslate\nfrom mtranslate import translate\nads = pd.read_csv('/work/playing-with-ads/ads_en_us.csv')\nads = ads.drop_duplicates(subset = 'value')\nads = ads.rename(columns = {'value':'text'})\nads = ads.iloc[0:29500]\nads.text = ads.text.apply(lambda x: translate(x, \"ru\", \"en\"))\nads.to_csv('ads_ru.csv', index = False)","block_group":"d846c62ee6bd411b891ce0f3e5f5a69e","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1719249818745,"execution_millis":13481,"deepnote_to_be_reexecuted":false,"cell_id":"3f6c67412fb2470c963bb3f429d24083","deepnote_cell_type":"code"},"source":"from io import open\nfrom conllu import parse_incr\nlst = []\ndata_file = open(\"/work/tagged_texts/vktexts.txt\", \"r\", encoding=\"utf-8\")\nfor tokenlist in parse_incr(data_file):\n    lst.append(tokenlist.metadata['text'])\n    if len(lst) >= 10000:\n        break\ndata_file = open(\"/work/tagged_texts/fbtexts.txt\", \"r\", encoding=\"utf-8\")\nfor tokenlist in parse_incr(data_file):\n    lst.append(tokenlist.metadata['text'])\n    if len(lst) >= 20000:\n        break\ndata_file = open(\"/work/tagged_texts/twtexts.txt\", \"r\", encoding=\"utf-8\")\nfor tokenlist in parse_incr(data_file):\n    lst.append(tokenlist.metadata['text'])\n    if len(lst) >= 30000:\n        break","block_group":"6d070f7de684406ab0bb921b6ea45b86","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1719249834531,"execution_millis":5775,"deepnote_to_be_reexecuted":false,"cell_id":"49f33682aaf840deb2f642db41b71639","deepnote_cell_type":"code"},"source":"df = pd.read_csv('/work/contextAdvertising1.csv')\ndf = df.dropna()\ndf['text'] = df.atitle + df.atext\ndf = df.drop_duplicates(subset = 'text')\ndf['is_ad'] = 1\ndf = df.sample(25000, random_state = 1)","block_group":"037d5bc9600c4f229671984d152a43a7","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1719249848015,"execution_millis":330,"deepnote_to_be_reexecuted":false,"cell_id":"537bcfd1124145948c0b84520c5aada1","deepnote_cell_type":"code"},"source":"twi = pd.read_csv('/work/rusentitweet_full.csv')\ntwi['is_ad'] = 0","block_group":"1edb9c34d11d4b3fb782cf39bc70b16a","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1719249849331,"execution_millis":4397,"deepnote_to_be_reexecuted":false,"cell_id":"7364483f76fb48cbb67f71132fb716df","deepnote_cell_type":"code"},"source":"ads =  pd.read_csv('ads_ru.csv')\nads['is_ad'] = 1\nads = ads[['text', 'is_ad']]\nads = ads.dropna()","block_group":"c4f3b499638a4364be7465d50d4d35b0","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1719249855115,"execution_millis":6445,"deepnote_to_be_reexecuted":false,"cell_id":"8a89e7b1bbd54e1189daf8affb7add66","deepnote_cell_type":"code"},"source":"anek = pd.read_csv('/work/vk-anekdots/anekdots_result.csv')\nanek['is_ad'] = 0\nanek = anek.dropna()\nanek = anek.drop_duplicates()\nanek = anek.sample(30000, random_state = 1)\nfin = pd.read_csv('/work/telegram-financial-sentiment-ru/mt-cleaned-labeled5.csv')\nfin['is_ad'] = 0\nfin = fin.dropna()\nfin = fin.drop_duplicates()\nfin = fin.sample(67000, random_state = 1).rename(columns = {'message':'text'})\nfin = fin[['text', 'is_ad']]","block_group":"9eeeb93a545f4dafa70912a7263958d9","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1719249863783,"execution_millis":55,"deepnote_to_be_reexecuted":false,"cell_id":"efc28d070ea149379025d9edfad285b7","deepnote_cell_type":"code"},"source":"tx = pd.DataFrame({'text': lst, 'is_ad':[0 for i in range(len(lst))]})\ntx = tx.drop_duplicates()\ndf = pd.concat([df[['text',  'is_ad']], twi[['text',  'is_ad']], tx, anek, fin, ads])\n","block_group":"eecc88db86574ef492e5656f7b606f74","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1719249905459,"execution_millis":75,"deepnote_to_be_reexecuted":false,"cell_id":"25ddedbe6e4e442d80ca174e63cf4be9","deepnote_cell_type":"code"},"source":"df = df.sample(frac=1, random_state = 1)","block_group":"c9b52768d4864ab6bd7218e02e058540","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1719249907397,"execution_millis":36,"deepnote_to_be_reexecuted":false,"cell_id":"4edfd0376c31432a90c73cef9be08b13","deepnote_cell_type":"code"},"source":"# df.to_csv('text.csv', index = False)","block_group":"20a14445007a4f9c874eb69600a3f7ac","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"374a75cc00ce4d2eae8efe3eec646003","deepnote_cell_type":"markdown"},"source":"2. Include Recurrent Layers:\nRecurrent layers like LSTM or GRU can capture sequential dependencies in the text data. You can add a Bidirectional LSTM layer.","block_group":"7c0b4f179fce4a73a082348262f1cf3c"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1719243340925,"execution_millis":350897,"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":false,"cell_id":"2ca409381d8d4bd7b48978f0bbafd648","deepnote_cell_type":"code"},"source":"#never gonna run on this machine\n\nvocab_size = len(tokenizer.word_index) + 1\nembedding_dim = 8\nmax_length = 1250\ntrunc_type='post'\npadding_type='post'\noov_tok = \"<OOV>\"\n\ntraining_padded = pad_sequences(tokenizer.texts_to_sequences(train.text), maxlen=max_length, padding=padding_type, truncating=trunc_type)\nvalid_padded = pad_sequences(tokenizer.texts_to_sequences(valid.text), maxlen=max_length, padding=padding_type, truncating=trunc_type)\ntesting_padded = pad_sequences(tokenizer.texts_to_sequences(test.text), maxlen=max_length, padding=padding_type, truncating=trunc_type)\nos.environ['PYTHONHASHSEED']=str(1)\ntf.random.set_seed(1)\nnp.random.seed(1)\nrandom.seed(1)\n\nvocab_size = len(tokenizer.word_index) + 1\n\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n    tf.keras.layers.GlobalAveragePooling1D(),\n    tf.keras.layers.Dense(200, activation='relu'),\n    tf.keras.layers.Dense(100, activation='relu'),\n    tf.keras.layers.Dense(50, activation='relu'),\n    tf.keras.layers.Dense(24, activation='relu'),\n    tf.keras.layers.Dense(12, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid'),\n])\n\n# Adam = tf.keras.optimizers.Adam(learning_rate=0.00001)\nAdam = 'Adam'\nmodel.compile(loss='binary_crossentropy',optimizer = Adam, metrics=['AUC'])\nmodel.fit(training_padded, train.is_ad, epochs=num_epochs, validation_data = (valid_padded, valid.is_ad), verbose=1) #validatio","block_group":"5595247fe6554696b23a02486f3d12bc","execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/3\n2024-06-24 15:36:05.836651: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 500000000 exceeds 10% of free system memory.\n  63/3125 [..............................] - ETA: 4:15:00 - loss: 0.5811 - auc: 0.5663","output_type":"stream"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn [21], line 35\u001b[0m\n\u001b[1;32m     33\u001b[0m Adam \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdam\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     34\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,optimizer \u001b[38;5;241m=\u001b[39m Adam, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAUC\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 35\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_padded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_ad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalid_padded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_ad\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"outputs_reference":"s3:deepnote-cell-outputs-production/be918d02-75ca-432b-a917-9b9ba752702e","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"4b5ec581aef542f6aec1620966e66e25","deepnote_cell_type":"markdown"},"source":"3. Add Dropout Layers:\nDropout layers help prevent overfitting by randomly dropping units during training.","block_group":"dccd6ed5c61245b6af38bc3056bb8293"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1719244777693,"execution_millis":464283,"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":false,"cell_id":"ba717b8d54b54e9c9212a8219572f95e","deepnote_cell_type":"code"},"source":"#OK, but needs more playing with\n\nvocab_size = len(tokenizer.word_index) + 1\nembedding_dim = 8\nmax_length = 1250\ntrunc_type='post'\npadding_type='post'\noov_tok = \"<OOV>\"\n\ntraining_padded = pad_sequences(tokenizer.texts_to_sequences(train.text), maxlen=max_length, padding=padding_type, truncating=trunc_type)\nvalid_padded = pad_sequences(tokenizer.texts_to_sequences(valid.text), maxlen=max_length, padding=padding_type, truncating=trunc_type)\ntesting_padded = pad_sequences(tokenizer.texts_to_sequences(test.text), maxlen=max_length, padding=padding_type, truncating=trunc_type)\nos.environ['PYTHONHASHSEED']=str(1)\ntf.random.set_seed(1)\nnp.random.seed(1)\nrandom.seed(1)\n\nvocab_size = len(tokenizer.word_index) + 1\n\nnum_epochs = 3\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n    tf.keras.layers.GlobalAveragePooling1D(),\n    tf.keras.layers.Dense(200, activation='relu'),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(100, activation='relu'),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(50, activation='relu'),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(24, activation='relu'),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(12, activation='relu'),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(1, activation='sigmoid'),\n])\n\n# Adam = tf.keras.optimizers.Adam(learning_rate=0.00001)\nAdam = 'Adam'\nmodel.compile(loss='binary_crossentropy',optimizer = Adam, metrics=['AUC'])\nmodel.fit(training_padded, train.is_ad, epochs=num_epochs, validation_data = (valid_padded, valid.is_ad), verbose=1) #validatio","block_group":"55f25c5712ad47bdbfed6acd56d735c6","execution_count":null,"outputs":[{"name":"stderr","text":"2024-06-24 16:00:25.269106: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n2024-06-24 16:00:25.269157: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n2024-06-24 16:00:25.269187: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (p-cd1fab30-834a-44c0-9ca0-4749a42969a7): /proc/driver/nvidia/version does not exist\n2024-06-24 16:00:25.269570: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\nEpoch 1/3\n2024-06-24 16:00:25.488405: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 500000000 exceeds 10% of free system memory.\n3123/3125 [============================>.] - ETA: 0s - loss: 0.2711 - auc: 0.94162024-06-24 16:02:40.915791: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 225000000 exceeds 10% of free system memory.\n3125/3125 [==============================] - 139s 44ms/step - loss: 0.2710 - auc: 0.9416 - val_loss: 0.1407 - val_auc: 0.9872\nEpoch 2/3\n3125/3125 [==============================] - 137s 44ms/step - loss: 0.1083 - auc: 0.9888 - val_loss: 0.0845 - val_auc: 0.9984\nEpoch 3/3\n3125/3125 [==============================] - 140s 45ms/step - loss: 0.0753 - auc: 0.9925 - val_loss: 0.0475 - val_auc: 0.9983\n","output_type":"stream"},{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"<keras.callbacks.History at 0x7f8efc0e9220>"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/0ce09527-c12d-4aa0-bc23-10ca3229f31c","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"210de394f1934ab28f78beb0b5032168","deepnote_cell_type":"markdown"},"source":"Batch Normalization:\nAdding batch normalization can stabilize and accelerate the training process.","block_group":"7e7dafa36e794085a46e50070de0a425"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1719245241989,"execution_millis":487515,"deepnote_to_be_reexecuted":false,"cell_id":"44ece73dd9244318b0428824e5d971d8","deepnote_cell_type":"code"},"source":"# On every fucking layer? No way this won't fuck it up. Try keeping only last one\n\nvocab_size = len(tokenizer.word_index) + 1\nembedding_dim = 8\nmax_length = 1250\ntrunc_type='post'\npadding_type='post'\noov_tok = \"<OOV>\"\n\ntraining_padded = pad_sequences(tokenizer.texts_to_sequences(train.text), maxlen=max_length, padding=padding_type, truncating=trunc_type)\nvalid_padded = pad_sequences(tokenizer.texts_to_sequences(valid.text), maxlen=max_length, padding=padding_type, truncating=trunc_type)\ntesting_padded = pad_sequences(tokenizer.texts_to_sequences(test.text), maxlen=max_length, padding=padding_type, truncating=trunc_type)\nos.environ['PYTHONHASHSEED']=str(1)\ntf.random.set_seed(1)\nnp.random.seed(1)\nrandom.seed(1)\n\nvocab_size = len(tokenizer.word_index) + 1\n\nnum_epochs = 3\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n    tf.keras.layers.GlobalAveragePooling1D(),\n    tf.keras.layers.Dense(200, activation='relu'),\n    # tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dense(100, activation='relu'),\n    # tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dense(50, activation='relu'),\n    # tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dense(24, activation='relu'),\n    # tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dense(12, activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dense(1, activation='sigmoid'),\n])\n\n\n# Adam = tf.keras.optimizers.Adam(learning_rate=0.00001)\nAdam = 'Adam'\nmodel.compile(loss='binary_crossentropy',optimizer = Adam, metrics=['AUC'])\nmodel.fit(training_padded, train.is_ad, epochs=num_epochs, validation_data = (valid_padded, valid.is_ad), verbose=1) #validatio","block_group":"13d375e9fc8f49e6b4f94dff57b23427","execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/3\n2024-06-24 16:08:11.110722: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 500000000 exceeds 10% of free system memory.\n3125/3125 [==============================] - ETA: 0s - loss: 0.0949 - auc: 0.98842024-06-24 16:10:32.991883: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 225000000 exceeds 10% of free system memory.\n3125/3125 [==============================] - 146s 46ms/step - loss: 0.0949 - auc: 0.9884 - val_loss: 0.0300 - val_auc: 0.9987\nEpoch 2/3\n3125/3125 [==============================] - 145s 46ms/step - loss: 0.0386 - auc: 0.9972 - val_loss: 0.4559 - val_auc: 0.9134\nEpoch 3/3\n3125/3125 [==============================] - 147s 47ms/step - loss: 0.0274 - auc: 0.9984 - val_loss: 0.0618 - val_auc: 0.9915\n","output_type":"stream"},{"output_type":"execute_result","execution_count":24,"data":{"text/plain":"<keras.callbacks.History at 0x7f8efdcd2a00>"},"metadata":{}}],"outputs_reference":"dbtable:cell_outputs/1f83f6f2-6e84-407d-96ee-ba2d7ecaff91","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"e69f26ae41ca4464952cf1f788093ab9","deepnote_cell_type":"markdown"},"source":"5. Optimizer Tuning:\nAdjusting the learning rate of the Adam optimizer can have a significant impact on model performance.","block_group":"aa63e84031774342a58ae4a959b0c020"},{"cell_type":"code","metadata":{"source_hash":null,"deepnote_to_be_reexecuted":true,"deepnote_app_block_visible":false,"cell_id":"ce5584abfa21429cb9e6b69f1c30aff2","deepnote_cell_type":"code"},"source":"#nope\nAdam = tf.keras.optimizers.Adam(learning_rate=0.00001)\nmodel.compile(loss='binary_crossentropy', optimizer=Adam, metrics=['AUC'])","block_group":"ec68d3051c714a4784d5dea0134be11f","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"bd296e82d3fb47178c0a0768fdfa459c","deepnote_cell_type":"markdown"},"source":"6. Increase Epochs and Use Early Stopping:\nIncreasing the number of epochs and implementing early stopping can help the model learn better while preventing overfitting.","block_group":"d02b429300494f2d9b8998e8ccd1e498"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1719249917581,"execution_millis":710309,"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":false,"cell_id":"a1348a3b719f40a78f94769ecde4e4af","deepnote_cell_type":"code"},"source":"# Good, but not as architecture changing option\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=3)\n\nvocab_size = len(tokenizer.word_index) + 1\nembedding_dim = 8\nmax_length = 1250\ntrunc_type='post'\npadding_type='post'\noov_tok = \"<OOV>\"\n\ntraining_padded = pad_sequences(tokenizer.texts_to_sequences(train.text), maxlen=max_length, padding=padding_type, truncating=trunc_type)\nvalid_padded = pad_sequences(tokenizer.texts_to_sequences(valid.text), maxlen=max_length, padding=padding_type, truncating=trunc_type)\ntesting_padded = pad_sequences(tokenizer.texts_to_sequences(test.text), maxlen=max_length, padding=padding_type, truncating=trunc_type)\nos.environ['PYTHONHASHSEED']=str(1)\ntf.random.set_seed(1)\nnp.random.seed(1)\nrandom.seed(1)\n\nvocab_size = len(tokenizer.word_index) + 1\n\nnum_epochs = 3\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n    # tf.keras.layers.Conv1D(20, 4), \n    tf.keras.layers.GlobalAveragePooling1D(),\n    # tf.keras.layers.Dense(300, activation='relu'),\n    # tf.keras.layers.Dropout(0.2),\n    # tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(200)),\n    tf.keras.layers.Dense(200, activation='relu'),\n    # tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(100, activation='relu'),\n    tf.keras.layers.Dense(50, activation='relu'),\n    tf.keras.layers.Dense(24, activation='relu'),\n    tf.keras.layers.Dense(12, activation='relu'),\n    # tf.keras.layers.BatchNormalization(1),\n    tf.keras.layers.Dense(1, activation='sigmoid'),\n])\n\n# Adam = tf.keras.optimizers.Adam(learning_rate=0.00001)\nAdam = 'Adam'\nmodel.compile(loss='binary_crossentropy',optimizer = Adam, metrics=['AUC'])\nmodel.fit(training_padded, train.is_ad, epochs=10, validation_data=(valid_padded, valid.is_ad), callbacks=[early_stopping], verbose=1)\n","block_group":"ec46f98a445145649fb3ee8894a54f98","execution_count":null,"outputs":[{"name":"stderr","text":"2024-06-24 17:25:44.059933: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n2024-06-24 17:25:44.059979: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n2024-06-24 17:25:44.060005: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (p-cd1fab30-834a-44c0-9ca0-4749a42969a7): /proc/driver/nvidia/version does not exist\n2024-06-24 17:25:44.060390: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\nEpoch 1/10\n2024-06-24 17:25:44.373320: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 500000000 exceeds 10% of free system memory.\n3125/3125 [==============================] - ETA: 0s - loss: 0.1391 - auc: 0.97942024-06-24 17:28:07.475240: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 225000000 exceeds 10% of free system memory.\n3125/3125 [==============================] - 147s 47ms/step - loss: 0.1391 - auc: 0.9794 - val_loss: 0.0280 - val_auc: 0.9993\nEpoch 2/10\n3125/3125 [==============================] - 130s 42ms/step - loss: 0.0329 - auc: 0.9979 - val_loss: 0.0166 - val_auc: 0.9993\nEpoch 3/10\n3125/3125 [==============================] - 134s 43ms/step - loss: 0.0235 - auc: 0.9987 - val_loss: 0.0326 - val_auc: 0.9978\nEpoch 4/10\n3125/3125 [==============================] - 136s 44ms/step - loss: 0.0166 - auc: 0.9991 - val_loss: 0.0371 - val_auc: 0.9993\nEpoch 5/10\n3125/3125 [==============================] - 133s 43ms/step - loss: 0.0147 - auc: 0.9992 - val_loss: 0.0186 - val_auc: 0.9995\n","output_type":"stream"},{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"<keras.callbacks.History at 0x7f6fa9952f40>"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/d12f3179-e7ce-47c4-b537-6d63300ddac5","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"a5b8a7863a2945a79f73aa5daadbc47e","deepnote_cell_type":"markdown"},"source":"7. Use Pre-trained Embeddings:\nUtilizing pre-trained embeddings like GloVe or Word2Vec can provide the model with richer semantic information from the start.","block_group":"7d38891719d742a5866d5ac22502e80a"},{"cell_type":"code","metadata":{"source_hash":null,"deepnote_to_be_reexecuted":true,"cell_id":"e8a443d0624044adaa9745cebeeba310","deepnote_cell_type":"code"},"source":"#never gonna run on this machine\n\nimport numpy as np\n\nembedding_index = {}\nwith open('glove.6B.100d.txt') as f:\n    for line in f:\n        values = line.split()\n        word = values[0]\n        coefs = np.asarray(values[1:], dtype='float32')\n        embedding_index[word] = coefs\n\nembedding_matrix = np.zeros((vocab_size, embedding_dim))\nfor word, i in tokenizer.word_index.items():\n    embedding_vector = embedding_index.get(word)\n    if embedding_vector is not None:\n        embedding_matrix[i] = embedding_vector\n\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], input_length=max_length, trainable=False),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n    tf.keras.layers.GlobalAveragePooling1D(),\n    tf.keras.layers.Dense(200, activation='relu'),\n    tf.keras.layers.Dense(100, activation='relu'),\n    tf.keras.layers.Dense(50, activation='relu'),\n    tf.keras.layers.Dense(24, activation='relu'),\n    tf.keras.layers.Dense(12, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid'),\n])","block_group":"6cd084141f7643ae80ed0fd1ecfc827b","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=cd1fab30-834a-44c0-9ca0-4749a42969a7' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_notebook_id":"59cd68f2ce42476eabfe08a5f25df266","deepnote_execution_queue":[]}}