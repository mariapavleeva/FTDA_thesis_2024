{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "37e4293b7aeb48abb9395eb50e842530",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2057,
    "execution_start": 1719175441777,
    "source_hash": null
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-26 09:28:53.485636: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fls = ['bestflats_ex - bestflats_ex.csv.csv',\n",
    "'bitkogan - bitkogan.csv.csv',\n",
    "'nlevshitstelegram - nlevshitstelegram.csv.csv',\n",
    "'promtyu - promtyu.csv.csv', \n",
    "'rbc_news - rbc_news.csv.csv',\n",
    "'pikabu - pikabu.csv.csv',\n",
    "'sale_caviar - sale_caviar.csv.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "547d8010ee044483ad6e623136cb53d2",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 185599,
    "execution_start": 1719175558069,
    "source_hash": null
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestflats_ex\n",
      "bitkogan\n",
      "nlevshitstelegram\n",
      "promtyu\n",
      "rbc_news\n",
      "pikabu\n",
      "sale_caviar\n"
     ]
    }
   ],
   "source": [
    "from datetime import timedelta\n",
    "import os\n",
    "ful = pd.DataFrame()\n",
    "for i in fls:\n",
    "    print(i.split(' ')[0])\n",
    "    df = pd.read_csv(i)\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "    filename = []\n",
    "    for j in range(len(df)):\n",
    "        if str(df.time.iloc[j]) + '.jpg' in os.listdir(i.split(' ')[0]):\n",
    "            filename.append(i.split(' ')[0]+ '/' + str(df.time.iloc[j]) + '.jpg')\n",
    "        else:\n",
    "            if str(df.time.iloc[j] + timedelta(seconds = 1)) + '.jpg' in os.listdir(i.split(' ')[0]):\n",
    "                filename.append(i.split(' ')[0]+ '/' + str(df.time.iloc[j] + timedelta(seconds = 1)) + '.jpg')\n",
    "            elif str(df.time.iloc[j] + timedelta(seconds = -1)) + '.jpg' in os.listdir(i.split(' ')[0]):\n",
    "                \n",
    "                filename.append(i.split(' ')[0]+ '/' + str(df.time.iloc[j] + timedelta(seconds = -1)) + '.jpg')\n",
    "            else:\n",
    "                filename.append(None)\n",
    "    df['filename'] = filename\n",
    "    ful = pd.concat([ful, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1162241/1314617571.py:4: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  ful = pd.concat([ful, no_pics])\n"
     ]
    }
   ],
   "source": [
    "no_pics = pd.concat([pd.read_csv('headlines_for_traders - df.csv.csv'), pd.read_csv('fatcat - df.csv.csv')])\n",
    "no_pics['time'] = None\n",
    "no_pics['filename'] = None\n",
    "ful = pd.concat([ful, no_pics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "647373aa55d04f7181f8d7cd841d2d92",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 94,
    "execution_start": 1719175036380,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "ful = ful.dropna(subset = ['message', 'ad'])\n",
    "ful = ful.sample(frac = 1, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Flatten, Concatenate, Conv2D, MaxPooling2D, Dropout,GlobalAveragePooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": "c1a8d20a9f724958b545fe5f4d8492ba",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1719175831354,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "import random\n",
    "os.environ['PYTHONHASHSEED']=str(1)\n",
    "tf.random.set_seed(1)\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "import pickle\n",
    "\n",
    "oov_tok = \"<OOV>\"\n",
    "tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(df.text)\n",
    "max_len_text = 1000 \n",
    "text_sequences = tokenizer.texts_to_sequences(ful['message'])\n",
    "text_data = pad_sequences(text_sequences, maxlen=max_len_text)\n",
    "\n",
    "\n",
    "image_data = []\n",
    "for filename in ful['filename']:\n",
    "    if filename is not None:\n",
    "        image_path = os.path.join(filename)\n",
    "        img = load_img(image_path, target_size=(224, 224))\n",
    "        img_array = img_to_array(img)\n",
    "        img_array /= 255.0  \n",
    "        image_data.append(img_array)\n",
    "    else:\n",
    "        image_data.append(np.zeros((224, 224, 3)))   \n",
    "image_data = np.array(image_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": "4f0dc9b1024949a6b395944e079d6565",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 2316,
    "execution_start": 1719174759644,
    "source_hash": null
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 1 variables whereas the saved optimizer has 44 variables. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "117/117 [==============================] - 99s 817ms/step - loss: 1.0895 - accuracy: 0.8761 - val_loss: 0.9750 - val_accuracy: 0.8937\n",
      "Epoch 2/6\n",
      "117/117 [==============================] - 95s 809ms/step - loss: 0.8462 - accuracy: 0.8936 - val_loss: 0.8096 - val_accuracy: 0.9076\n",
      "Epoch 3/6\n",
      "117/117 [==============================] - 93s 794ms/step - loss: 0.7002 - accuracy: 0.9062 - val_loss: 0.6655 - val_accuracy: 0.9098\n",
      "Epoch 4/6\n",
      "117/117 [==============================] - 98s 837ms/step - loss: 0.5803 - accuracy: 0.9097 - val_loss: 0.5465 - val_accuracy: 0.9141\n",
      "Epoch 5/6\n",
      "117/117 [==============================] - 95s 816ms/step - loss: 0.4833 - accuracy: 0.9081 - val_loss: 0.4703 - val_accuracy: 0.9162\n",
      "Epoch 6/6\n",
      "117/117 [==============================] - 95s 813ms/step - loss: 0.4259 - accuracy: 0.9159 - val_loss: 0.4201 - val_accuracy: 0.9173\n",
      "37/37 [==============================] - 7s 192ms/step - loss: 0.3834 - accuracy: 0.9270\n",
      "Test Loss: 0.3834344446659088\n",
      "Test Accuracy: 0.9269759654998779\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embedding_dim = 8\n",
    "max_length = 1000\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<OOV>\"\n",
    "\n",
    "\n",
    "inputs_text = Input(shape=(max_len_text,))\n",
    "inputs_image = Input(shape=(224, 224, 3))\n",
    "\n",
    "embedding_dim = 8  \n",
    "text_model = Embedding(vocab_size, embedding_dim, input_length=max_length)(inputs_text)\n",
    "text_model = GlobalAveragePooling1D()(text_model)\n",
    "text_model = Dense(200, activation='relu')(text_model)\n",
    "text_model = Dense(100, activation='relu')(text_model)\n",
    "text_model = Dense(50, activation='relu')(text_model)\n",
    "text_model = Dense(24, activation='relu')(text_model)\n",
    "text_model = Dense(12, activation='relu')(text_model)\n",
    "\n",
    "image_model = Conv2D(32, (3, 3), activation='relu')(inputs_image)\n",
    "image_model = MaxPooling2D((2, 2))(image_model)\n",
    "image_model = Conv2D(64, (3, 3), activation='relu')(image_model)\n",
    "image_model = MaxPooling2D((2, 2))(image_model)\n",
    "image_model = Conv2D(128, (3, 3), activation='relu')(image_model)\n",
    "image_model = MaxPooling2D((2, 2))(image_model)\n",
    "image_model = Flatten()(image_model)\n",
    "image_model = Dense(256, activation='relu')(image_model)\n",
    "image_model = Dropout(0.5)(image_model)\n",
    "\n",
    "concatenated = Concatenate()([text_model, image_model])\n",
    "output = Dense(1, activation='sigmoid')(concatenated)\n",
    "    \n",
    "model = Model(inputs=[inputs_text, inputs_image], outputs=output)\n",
    "Adam = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam, metrics=['accuracy'])\n",
    "model.load_weights('mm_weights.weights.h5')\n",
    "\n",
    "X_text_train, X_text_test, X_image_train, X_image_test, y_train, y_test = train_test_split(\n",
    "    text_data, image_data, ful['ad'], test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "model.fit([X_text_train, X_image_train], y_train, batch_size=32, epochs=6, validation_split=0.2)\n",
    "\n",
    "loss, accuracy = model.evaluate([X_text_test, X_image_test], y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "fb6384eedaf444068d7ccae9d89681ce",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
