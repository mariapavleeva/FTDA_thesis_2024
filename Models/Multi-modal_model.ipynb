{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "37e4293b7aeb48abb9395eb50e842530",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2057,
    "execution_start": 1719175441777,
    "source_hash": null
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 21:20:37.926729: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import os\n",
    "import random\n",
    "# from mtranslate import translate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fls = ['bestflats_ex - bestflats_ex.csv.csv',\n",
    "'bitkogan - bitkogan.csv.csv',\n",
    "'nlevshitstelegram - nlevshitstelegram.csv.csv',\n",
    "'promtyu - promtyu.csv.csv', \n",
    "'rbc_news - rbc_news.csv.csv',\n",
    "'pikabu - pikabu.csv.csv',\n",
    "'sale_caviar - sale_caviar.csv.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "547d8010ee044483ad6e623136cb53d2",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 185599,
    "execution_start": 1719175558069,
    "source_hash": null
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestflats_ex\n",
      "bitkogan\n",
      "nlevshitstelegram\n",
      "promtyu\n",
      "rbc_news\n",
      "pikabu\n",
      "sale_caviar\n"
     ]
    }
   ],
   "source": [
    "from datetime import timedelta\n",
    "import os\n",
    "ful = pd.DataFrame()\n",
    "for i in fls:\n",
    "    print(i.split(' ')[0])\n",
    "    df = pd.read_csv(i)\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "    filename = []\n",
    "    #os.listdir('/work/' + i.split(' ')[0])\n",
    "    for j in range(len(df)):\n",
    "        if str(df.time.iloc[j]) + '.jpg' in os.listdir(i.split(' ')[0]):\n",
    "            filename.append(i.split(' ')[0]+ '/' + str(df.time.iloc[j]) + '.jpg')\n",
    "        else:\n",
    "            if str(df.time.iloc[j] + timedelta(seconds = 1)) + '.jpg' in os.listdir(i.split(' ')[0]):\n",
    "                filename.append(i.split(' ')[0]+ '/' + str(df.time.iloc[j] + timedelta(seconds = 1)) + '.jpg')\n",
    "            elif str(df.time.iloc[j] + timedelta(seconds = -1)) + '.jpg' in os.listdir(i.split(' ')[0]):\n",
    "                \n",
    "                filename.append(i.split(' ')[0]+ '/' + str(df.time.iloc[j] + timedelta(seconds = -1)) + '.jpg')\n",
    "            else:\n",
    "                filename.append(None)\n",
    "    df['filename'] = filename\n",
    "    ful = pd.concat([ful, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "647373aa55d04f7181f8d7cd841d2d92",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 94,
    "execution_start": 1719175036380,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "ful = ful.dropna(subset = ['message', 'ad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Flatten, Concatenate, Conv2D, MaxPooling2D, Dropout,GlobalAveragePooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "c1a8d20a9f724958b545fe5f4d8492ba",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1719175831354,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "import random\n",
    "os.environ['PYTHONHASHSEED']=str(1)\n",
    "tf.random.set_seed(1)\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "import pickle\n",
    "\n",
    "oov_tok = \"<OOV>\"\n",
    "tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(df.text)\n",
    "max_len_text = 1000 \n",
    "text_sequences = tokenizer.texts_to_sequences(ful['message'])\n",
    "text_data = pad_sequences(text_sequences, maxlen=max_len_text)\n",
    "image_data = []\n",
    "for filename in ful['filename']:\n",
    "    if filename is not None:\n",
    "        # Load and preprocess image\n",
    "        image_path = os.path.join(filename)\n",
    "        img = load_img(image_path, target_size=(224, 224))\n",
    "        img_array = img_to_array(img)\n",
    "        img_array /= 255.0  # Normalize pixel values to [0, 1]\n",
    "        image_data.append(img_array)\n",
    "    else:\n",
    "        # If no image provided, use zeros as placeholder\n",
    "        image_data.append(np.zeros((224, 224, 3)))   # Assuming image size is 224x224 and 3 channels\n",
    "image_data = np.array(image_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "4f0dc9b1024949a6b395944e079d6565",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 2316,
    "execution_start": 1719174759644,
    "source_hash": null
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 1 variables whereas the saved optimizer has 44 variables. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "310/310 [==============================] - 88s 276ms/step - loss: 0.6176 - auc: 0.5625 - val_loss: 0.3459 - val_auc: 0.5324\n",
      "Epoch 2/5\n",
      "310/310 [==============================] - 81s 262ms/step - loss: 0.2974 - auc: 0.5745 - val_loss: 0.2698 - val_auc: 0.6116\n",
      "Epoch 3/5\n",
      "310/310 [==============================] - 83s 268ms/step - loss: 0.2405 - auc: 0.6535 - val_loss: 0.2555 - val_auc: 0.7028\n",
      "Epoch 4/5\n",
      "310/310 [==============================] - 82s 265ms/step - loss: 0.2144 - auc: 0.7165 - val_loss: 0.2439 - val_auc: 0.7203\n",
      "Epoch 5/5\n",
      "310/310 [==============================] - 80s 260ms/step - loss: 0.2003 - auc: 0.7413 - val_loss: 0.2501 - val_auc: 0.6674\n",
      "25/25 [==============================] - 5s 183ms/step - loss: 0.2615 - auc: 0.5447\n",
      "Test Loss: 0.26154521107673645\n",
      "Test Accuracy: 0.5447075366973877\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embedding_dim = 8\n",
    "max_length = 1000\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<OOV>\"\n",
    "\n",
    "\n",
    "inputs_text = Input(shape=(max_len_text,))\n",
    "inputs_image = Input(shape=(224, 224, 3))\n",
    "\n",
    "embedding_dim = 8  \n",
    "text_model = Embedding(vocab_size, embedding_dim, input_length=max_length)(inputs_text)\n",
    "text_model = GlobalAveragePooling1D()(text_model)\n",
    "text_model = Dense(200, activation='relu')(text_model)\n",
    "text_model = Dense(100, activation='relu')(text_model)\n",
    "text_model = Dense(50, activation='relu')(text_model)\n",
    "text_model = Dense(24, activation='relu')(text_model)\n",
    "text_model = Dense(12, activation='relu')(text_model)\n",
    "\n",
    "image_model = Conv2D(32, (3, 3), activation='relu')(inputs_image)\n",
    "image_model = MaxPooling2D((2, 2))(image_model)\n",
    "image_model = Conv2D(64, (3, 3), activation='relu')(image_model)\n",
    "image_model = MaxPooling2D((2, 2))(image_model)\n",
    "image_model = Conv2D(128, (3, 3), activation='relu')(image_model)\n",
    "image_model = MaxPooling2D((2, 2))(image_model)\n",
    "image_model = Flatten()(image_model)\n",
    "image_model = Dense(256, activation='relu')(image_model)\n",
    "image_model = Dropout(0.5)(image_model)\n",
    "\n",
    "concatenated = Concatenate()([text_model, image_model])\n",
    "output = Dense(1, activation='sigmoid')(concatenated)\n",
    "    \n",
    "model = Model(inputs=[inputs_text, inputs_image], outputs=output)\n",
    "Adam = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam, metrics=['accuracy'])\n",
    "model.load_weights('mm_weights.weights.h5')\n",
    "\n",
    "X_text_train, X_text_test, X_image_train, X_image_test, y_train, y_test = train_test_split(\n",
    "    text_data, image_data, ful['ad'], test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "model.fit([X_text_train, X_image_train], y_train, batch_size=8, epochs=5, validation_split=0.2)\n",
    "\n",
    "loss, accuracy = model.evaluate([X_text_test, X_image_test], y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch 1/10\n",
    "# 78/78 [==============================] - 66s 817ms/step - loss: 0.8458 - accuracy: 0.8629 - val_loss: 0.4481 - val_accuracy: 0.8918\n",
    "# Epoch 2/10\n",
    "# 78/78 [==============================] - 64s 825ms/step - loss: 0.3961 - accuracy: 0.9021 - val_loss: 0.3438 - val_accuracy: 0.9079\n",
    "# Epoch 3/10\n",
    "# 78/78 [==============================] - 62s 797ms/step - loss: 0.3045 - accuracy: 0.9236 - val_loss: 0.2977 - val_accuracy: 0.9111\n",
    "# Epoch 4/10\n",
    "# 78/78 [==============================] - 64s 822ms/step - loss: 0.2778 - accuracy: 0.9248 - val_loss: 0.2824 - val_accuracy: 0.9273\n",
    "# Epoch 5/10\n",
    "# 78/78 [==============================] - 62s 798ms/step - loss: 0.2471 - accuracy: 0.9373 - val_loss: 0.2718 - val_accuracy: 0.9289\n",
    "# Epoch 6/10\n",
    "# 78/78 [==============================] - 62s 792ms/step - loss: 0.2289 - accuracy: 0.9422 - val_loss: 0.2704 - val_accuracy: 0.9257\n",
    "# Epoch 7/10\n",
    "# 78/78 [==============================] - 62s 790ms/step - loss: 0.2082 - accuracy: 0.9430 - val_loss: 0.2618 - val_accuracy: 0.9289\n",
    "# Epoch 8/10\n",
    "# 78/78 [==============================] - 62s 802ms/step - loss: 0.2063 - accuracy: 0.9422 - val_loss: 0.2676 - val_accuracy: 0.9257\n",
    "# Epoch 9/10\n",
    "# 78/78 [==============================] - 61s 786ms/step - loss: 0.1955 - accuracy: 0.9450 - val_loss: 0.2560 - val_accuracy: 0.9289\n",
    "# Epoch 10/10\n",
    "# 78/78 [==============================] - 61s 784ms/step - loss: 0.1896 - accuracy: 0.9442 - val_loss: 0.2489 - val_accuracy: 0.9289\n",
    "# 25/25 [==============================] - 5s 184ms/step - loss: 0.2726 - accuracy: 0.9341\n",
    "# Test Loss: 0.2726414203643799\n",
    "# Test Accuracy: 0.934108555316925"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch 1/10\n",
    "# 155/155 [==============================] - 74s 459ms/step - loss: 0.7457 - accuracy: 0.8658 - val_loss: 0.3905 - val_accuracy: 0.8966\n",
    "# Epoch 2/10\n",
    "# 155/155 [==============================] - 68s 442ms/step - loss: 0.3374 - accuracy: 0.9118 - val_loss: 0.2915 - val_accuracy: 0.9144\n",
    "# Epoch 3/10\n",
    "# 155/155 [==============================] - 69s 448ms/step - loss: 0.2616 - accuracy: 0.9325 - val_loss: 0.2641 - val_accuracy: 0.9257\n",
    "# Epoch 4/10\n",
    "# 155/155 [==============================] - 68s 437ms/step - loss: 0.2362 - accuracy: 0.9361 - val_loss: 0.2528 - val_accuracy: 0.9289\n",
    "# Epoch 5/10\n",
    "# 155/155 [==============================] - 68s 441ms/step - loss: 0.2179 - accuracy: 0.9402 - val_loss: 0.2507 - val_accuracy: 0.9289\n",
    "# Epoch 6/10\n",
    "# 155/155 [==============================] - 68s 437ms/step - loss: 0.2046 - accuracy: 0.9454 - val_loss: 0.2452 - val_accuracy: 0.9289\n",
    "# Epoch 7/10\n",
    "# 155/155 [==============================] - 68s 440ms/step - loss: 0.1956 - accuracy: 0.9474 - val_loss: 0.2461 - val_accuracy: 0.9289\n",
    "# Epoch 8/10\n",
    "# 155/155 [==============================] - 68s 440ms/step - loss: 0.1795 - accuracy: 0.9499 - val_loss: 0.2793 - val_accuracy: 0.9273\n",
    "# Epoch 9/10\n",
    "# 155/155 [==============================] - 68s 441ms/step - loss: 0.1739 - accuracy: 0.9523 - val_loss: 0.2620 - val_accuracy: 0.9289\n",
    "# Epoch 10/10\n",
    "# 155/155 [==============================] - 68s 439ms/step - loss: 0.1665 - accuracy: 0.9523 - val_loss: 0.2605 - val_accuracy: 0.9289\n",
    "# 25/25 [==============================] - 4s 178ms/step - loss: 0.2883 - accuracy: 0.9328\n",
    "# Test Loss: 0.28826966881752014\n",
    "# Test Accuracy: 0.9328165650367737\n"
   ]
  }
 ],
 "metadata": {
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "fb6384eedaf444068d7ccae9d89681ce",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
